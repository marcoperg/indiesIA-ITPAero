{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ccde8da",
   "metadata": {},
   "source": [
    "belen.minguez@itpaero.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfced47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_AXIS = 'X'\n",
    "assert TARGET_AXIS in ('X', 'Z', 'B', 'C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2a9c473-9bde-4dac-87a1-a49e06c5487f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlgb\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostRegressor\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold, TimeSeriesSplit\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a0d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.7-cp39-cp39-macosx_11_0_universal2.whl (27.1 MB)\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[32m22.9/27.1 MB\u001b[0m \u001b[31m296.9 kB/s\u001b[0m eta \u001b[36m0:00:14\u001b[0m:15\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1433f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ITPAero_dataset.csv\", sep=';')\n",
    "df['FBrochado'] = pd.to_datetime(df['FBrochado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abab0579",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df[f'{TARGET_AXIS}CMM'] + df[f'{TARGET_AXIS}C']\n",
    "\n",
    "df['targetX'] = df[f'XCMM'] + df[f'XC']\n",
    "df['targetZ'] = df[f'ZCMM'] + df[f'ZC']\n",
    "df['targetB'] = df[f'BCMM'] + df[f'BC']\n",
    "df['targetC'] = df[f'CCMM'] + df[f'CC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ca34654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.target.isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58443619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_feature_engineering(df):\n",
    "    \"\"\"\n",
    "    Perform feature engineering on time series data.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame\n",
    "    target_column (str): Name of the target variable column\n",
    "    date_column (str): Name of the date column\n",
    "    window_sizes (list): List of rolling window sizes (default: [7, 14, 30])\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with new engineered features\n",
    "    \"\"\"\n",
    "    \n",
    "    for window in [3, 7, 14, 30]:\n",
    "        # Rolling mean\n",
    "        df[f'{group}{target_column}_rolling_mean{window}'] = df[target_column].rolling(window=window).mean().shift(1)\n",
    "        \n",
    "        # Rolling standard deviation\n",
    "        df[f'{group}{target_column}_rolling_std{window}'] = df[target_column].rolling(window=window).std().shift(1)\n",
    "        \n",
    "        # Rolling median\n",
    "        df[f'{group}{target_column}_rolling_median{window}'] = df[target_column].rolling(window=window).median().shift(1)\n",
    "        \n",
    "        # Rolling min\n",
    "        df[f'{group}{target_column}_rolling_min{window}'] = df[target_column].rolling(window=window).min().shift(1)\n",
    "        \n",
    "        # Rolling max\n",
    "        df[f'{group}{target_column}_rolling_max{window}'] = df[target_column].rolling(window=window).max().shift(1)\n",
    "        \n",
    "        # Rolling skewness\n",
    "        df[f'{group}{target_column}_rolling_skew{window}'] = df[target_column].rolling(window=window).skew().shift(1)\n",
    "        \n",
    "        # Rolling kurtosis\n",
    "        df[f'{group}{target_column}_rolling_kurtosis{window}'] = df[target_column].rolling(window=window).kurt().shift(1)\n",
    "        \n",
    "        # Exponential moving average\n",
    "        df[f'{group}{target_column}_ema{window}'] = df[target_column].ewm(span=window, adjust=False).mean().shift(1)\n",
    "    \n",
    "    # Lag features\n",
    "    for lag in [1, 3, 7, 14, 30]:\n",
    "        df[f'{group}{target_column}_lag{lag}'] = df[target_column].shift(lag)\n",
    "    \n",
    "    # Reset index to bring date column back\n",
    "#    df = df.reset_index(drop)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df[\"BrochaSN_Utillaje\"] = str(df[\"BrochaSN\"]) + str(df[\" Utillaje\"])\n",
    "df[\"BrochaSN_NBrochasHSS\"] = str(df[\"BrochaSN\"]) + str(df[\"NBrochasHSS\"])\n",
    "df[\"BrochaSN_ndisco\"] = str(df[\"BrochaSN\"]) + str(df[\"NDisco\"])\n",
    "df[\"Brocha_ndisco\"] = str(df[\"Brocha\"]) + str(df[\"NDisco\"])\n",
    "df[\"Maquina_BrochaSN_NBrochasHSS\"] = str(df[\"Maquina\"]) + str(df[\"BrochaSN_NBrochasHSS\"])\n",
    "df[\"Maquina_BrochaSN\"] = str(df[\"Maquina\"]) + str(df[\"BrochaSN\"])\n",
    "\n",
    "\n",
    "for target_column in ['targetX', 'targetZ', 'targetB', 'targetC']:\n",
    "    for group in ['BrochaSN_Utillaje',\n",
    "                  'Maquina',\n",
    "                  ' Utillaje', \n",
    "                  'Brocha',\n",
    "                  'Brocha_ndisco',\n",
    "                  'Maquina_BrochaSN',\n",
    "                  'BrochaSN_ndisco',\n",
    "                  'BrochaSN',\n",
    "                  'BrochaSN_NBrochasHSS', \n",
    "                  'Maquina_BrochaSN_NBrochasHSS']:\n",
    "\n",
    "        df = df.groupby(group, group_keys=False).apply(time_series_feature_engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471831f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all object columns to categorical\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93dcb0e9-a714-462b-b226-ec0759ef40b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = df['FBrochado'] < '2024-7-1'\n",
    "test_idx = df['FBrochado'] >= '2024-7-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6071561-9543-4f66-bf37-89db90572d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FBrochado'] = df['FBrochado'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a515ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important after FE\n",
    "df = df[df.DUMMY == 'FALSO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "addeabf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\n",
    "    'XCMM',\n",
    "    'ZCMM',\n",
    "    'BCMM',\n",
    "    'CCMM',\n",
    "    'BrochaSN',\n",
    "    'PartNumber',\n",
    "    'FBrochado',\n",
    "    'XC',\n",
    "    'ZC',\n",
    "    'BC',\n",
    "    'CC',\n",
    "    'OrdenFabricacion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03564fea-9efe-406a-9a1a-d8f4b7c3da37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/h_b6fb4s5kx77mr9j442kbh80000gn/T/ipykernel_90278/1766937709.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_train = df[train_idx]\n",
      "/var/folders/th/h_b6fb4s5kx77mr9j442kbh80000gn/T/ipykernel_90278/1766937709.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_test = df[test_idx]\n"
     ]
    }
   ],
   "source": [
    "df_train = df[train_idx]\n",
    "df_test = df[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47716df2-e6a2-46ed-b7e9-dbd498e968a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['target']\n",
    "X = df_train.drop(columns=['target', 'targetX', 'targetZ', 'targetB', 'targetC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dfad138",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test['target']\n",
    "X_test = df_test.drop(columns=['target', 'targetX', 'targetZ', 'targetB', 'targetC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85ec546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X.dtypes[X.dtypes == 'category'].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36baa303-e355-4145-88f8-f4750a46952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingModel(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, estimators):\n",
    "        super().__init__()\n",
    "        self.estimators = estimators\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_preds_lgbm = [estimator['lgbm'].predict(X) for estimator in self.estimators]\n",
    "        y_preds_xgb = [estimator['xgb'].predict(X) for estimator in self.estimators]\n",
    "        y_preds_cat = [estimator['cat'].predict(X) for estimator in self.estimators]\n",
    "\n",
    "        y_preds = np.mean([y_preds_lgbm, y_preds_cat], axis=0)\n",
    "        #weights = np.arange(1, len(y_preds) + 1)\n",
    "        #weights = np.ones_like(y_preds)\n",
    "        #weights = np.exp(np.linspace(0, 2, len(y_preds)))\n",
    "        #weights = np.linspace(1, len(y_preds), len(y_preds)) ** 2\n",
    "        #weights = np.linspace(1, len(y_preds), len(y_preds)) ** 3\n",
    "        #weights = np.linspace(1, len(y_preds), len(y_preds)) ** 4\n",
    "        weights = np.linspace(1, len(y_preds), len(y_preds)) ** 5\n",
    "\n",
    "\n",
    "        #weights = np.log(np.linspace(1, len(y_preds) + 1, len(y_preds)))\n",
    "        #x = np.linspace(-6, 6, len(y_preds))\n",
    "        #weights = 1 / (1 + np.exp(-x))\n",
    "\n",
    "        return np.average(y_preds, weights=weights, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aab2b611-473e-45af-9dfd-df7adb141515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(params):\n",
    "    n_splits = 5\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits, test_size=100)\n",
    "    fitted_models = []\n",
    "    rmses = []\n",
    "    max_abss = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(tqdm(tscv.split(X), total=n_splits)):\n",
    "        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_valid, y_valid = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "        modelLGBM = lgb.LGBMRegressor(**params)\n",
    "        modelXGB = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            n_estimators=1000,\n",
    "            max_depth=4,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            enable_categorical=True\n",
    "        )\n",
    "        \n",
    "        modelCat = CatBoostRegressor(\n",
    "            iterations=1000,\n",
    "            learning_rate=0.1,\n",
    "            depth=6,\n",
    "            loss_function='RMSE',\n",
    "            eval_metric='RMSE',\n",
    "            random_seed=0,\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        model.Catfit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=(X_valid, y_test),\n",
    "            # use_best_model=True,\n",
    "            cat_features=cat_cols,  # Pass the list of categorical column indices\n",
    "        )\n",
    "\n",
    "        modelXGB.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "        )\n",
    "\n",
    "        modelLGBM.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            #callbacks=[lgb.log_evaluation(200), lgb.early_stopping(60)]\n",
    "            callbacks=[lgb.early_stopping(50, verbose=False)]\n",
    "        )\n",
    "        \n",
    "        fitted_models.append({'lgbm': modelLGBM, 'xgb': modelXGB, 'cat': modelCat})\n",
    "\n",
    "        y_pred_valid = np.mean([modelLGBM.predict(X_valid), \n",
    "                                modelXGB.predict(X_valid)], axis=0)\n",
    "        rmse = root_mean_squared_error(y_valid, y_pred_valid)\n",
    "        max_abs = max(abs(y_valid - y_pred_valid))\n",
    "        rmses.append(rmse)\n",
    "        max_abss.append(max_abs)\n",
    "\n",
    "    model = VotingModel(fitted_models)\n",
    "\n",
    "    return model, rmses, max_abss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c8a886",
   "metadata": {},
   "source": [
    "# Polbo galego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3b1e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Create or load the study\n",
    "def create_or_load_study(study_name, storage=None):\n",
    "    try:\n",
    "        study = joblib.load(f\"optuna/{study_name}.pkl\")\n",
    "        print(f\"Loaded study '{study_name}' from file.\")\n",
    "    except FileNotFoundError:\n",
    "        study = optuna.create_study(study_name=study_name, storage=storage, direction='maximize')\n",
    "        print(f\"Created new study '{study_name}'.\")\n",
    "    return study\n",
    "\n",
    "# Function to save the study\n",
    "def save_study(study, study_name):\n",
    "    joblib.dump(study, f\"optuna/{study_name}.pkl\")\n",
    "    print(f\"Study '{study_name}' saved to file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5260be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # set up the parameters to be optimized\n",
    "    param = {\n",
    "        'metric': 'rmse', \n",
    "        #'random_state': seed,\n",
    "        'n_estimators': 10000,\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-4, 10.0,log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-4, 10.0,log=True),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2,log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 8),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 40, 100),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n",
    "        'cat_smooth': trial.suggest_int('cat_smooth', 1, 100),\n",
    "        'force_col_wise':True,\n",
    "        'min_data_in_leaf': 30,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    model, rmses, max_abss = train(param)\n",
    "    #y_pred = model.predict(X_test,)\n",
    "    #return root_mean_squared_error(y_test, y_pred)\n",
    "    return np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd481b21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded study 'optuna-X' from file.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "study_name = f'optuna-{TARGET_AXIS}'\n",
    "study = create_or_load_study(study_name)\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    #print(f\"Best value: {study.best_value}, Best params: {trial.best_trial.params}\")\n",
    "\n",
    "    study_df = study.trials_dataframe()\n",
    "    save_study(study, study_name)\n",
    "    study_df.to_csv('optuna.csv', index=False)\n",
    "\n",
    "\n",
    "#study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d080b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_alpha': 9.563614073230701,\n",
       " 'reg_lambda': 2.0037425474007504,\n",
       " 'colsample_bytree': 0.3724836970198203,\n",
       " 'subsample': 0.5450904836262437,\n",
       " 'learning_rate': 0.00829142573909476,\n",
       " 'max_depth': 7,\n",
       " 'num_leaves': 81,\n",
       " 'min_child_samples': 32,\n",
       " 'cat_smooth': 99}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fb48e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_params = {\n",
    "    'metric': 'rmse',\n",
    "    'n_estimators': 10000,\n",
    "'reg_alpha': 0.009276932353966864, 'reg_lambda': 0.0009662650305581986, 'colsample_bytree': 0.6698903262487423, 'subsample': 0.6732087036287323, 'learning_rate': 0.01254395613011985, 'max_depth': 6, 'num_leaves': 68, 'min_child_samples': 29, 'cat_smooth': 46,    'cat_smooth': 6,\n",
    "    'force_col_wise':True,\n",
    "    'min_data_in_leaf': 30,\n",
    "    'verbose': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bb27ecf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd84bac874d34766918037974aa672db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'CatBoostRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m10000\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstudy\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m      6\u001b[0m }\n\u001b[0;32m----> 8\u001b[0m model, rmses, max_abss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     12\u001b[0m modelLGBM \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m     13\u001b[0m modelXGB \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor(\n\u001b[1;32m     14\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m modelCat \u001b[38;5;241m=\u001b[39m \u001b[43mCatBoostRegressor\u001b[49m(\n\u001b[1;32m     25\u001b[0m     iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     26\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m     27\u001b[0m     depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[1;32m     28\u001b[0m     loss_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     29\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     30\u001b[0m     random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     31\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     32\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m model\u001b[38;5;241m.\u001b[39mCatfit(\n\u001b[1;32m     36\u001b[0m     X_train,\n\u001b[1;32m     37\u001b[0m     y_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     cat_features\u001b[38;5;241m=\u001b[39mcat_cols,  \u001b[38;5;66;03m# Pass the list of categorical column indices\u001b[39;00m\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     43\u001b[0m modelXGB\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     44\u001b[0m     X_train, y_train,\n\u001b[1;32m     45\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39m[(X_val, y_val)],\n\u001b[1;32m     46\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CatBoostRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'metric': 'rmse',\n",
    "    'n_estimators': 10000,\n",
    "    'verbose': -1,\n",
    "    **study.best_params\n",
    "}\n",
    "\n",
    "model, rmses, max_abss = train(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f3f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(rmses), np.mean(max_abss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3184800",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc68d8c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "root_mean_squared_error(y_test, y_pred), max(abs(y_test-y_pred)), r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58fb9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum((y_test >= 0) == (y_pred >= 0)) / len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae94a3fd",
   "metadata": {},
   "source": [
    "(0.20189549398215334, 0.8893085024191398, 0.2079495875486005)\n",
    "antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ea177",
   "metadata": {},
   "outputs": [],
   "source": [
    "for local_model in model.estimators:\n",
    "    y_pred = local_model['lgbm'].predict(X_test)\n",
    "    print(root_mean_squared_error(y_test, y_pred), max(abs(y_test-y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb642ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(model.estimators[-1]['lgbm'])\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test, X_test.columns, plot_size=0.3, max_display=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912832d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# compute SHAP values\n",
    "explainer = shap.Explainer(model.estimators[-1], feature_perturbation=\"tree_path_dependent\")\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "index = 508\n",
    "\n",
    "print(f\"Predicted {y_pred[index]} True:{y_test[index]}\")\n",
    "shap.plots.waterfall(shap_values[index], max_display=20)\n",
    "X_test.iloc[index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
